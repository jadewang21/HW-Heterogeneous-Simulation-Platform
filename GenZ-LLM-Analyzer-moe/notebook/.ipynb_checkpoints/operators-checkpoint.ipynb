{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenZ import get_model_df, get_summary_table, System, create_inference_moe_prefill_layer, create_inference_moe_decode_layer\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def test_dense_LLM_prefill():\n",
    "    # Delete the current CSV file if it exists\n",
    "    if os.path.exists('/tmp/current_llama2_7b_prefill_on_TPU.csv'):\n",
    "        os.remove('/tmp/current_llama2_7b_prefill_on_TPU.csv')\n",
    "\n",
    "    # Generate the current result\n",
    "    TPU = System(flops=300, offchip_mem_bw=1200, compute_efficiency=0.8, memory_efficiency=0.8, bits='bf16')\n",
    "\n",
    "    # Save the current result to a CSV file\n",
    "    current_df = get_model_df(model=create_inference_moe_prefill_layer(1024, \"llama2_7b\"), system=TPU)\n",
    "    current_df.to_csv('/tmp/current_llama2_7b_prefill_on_TPU.csv', index=False)\n",
    "\n",
    "\n",
    "def test_dense_LLM_decode():\n",
    "    # Delete the current CSV file if it exists\n",
    "    if os.path.exists('/tmp/current_llama2_7b_decode_on_TPU.csv'):\n",
    "        os.remove('/tmp/current_llama2_7b_decode_on_TPU.csv')\n",
    "\n",
    "\n",
    "    # Generate the current result\n",
    "    TPU = System(flops=300, offchip_mem_bw=1200, compute_efficiency=0.8, memory_efficiency=0.8, bits='bf16')\n",
    "\n",
    "    # Save the current result to a CSV file\n",
    "    current_df = get_model_df(model=create_inference_moe_decode_layer(1024, \"llama2_7b\"), system=TPU)\n",
    "    current_df.to_csv('/tmp/current_llama2_7b_decode_on_TPU.csv', index=False)\n",
    "\n",
    "    # Reload the saved current result\n",
    "    reloaded_current_df = pd.read_csv('/tmp/current_llama2_7b_decode_on_TPU.csv')\n",
    "\n",
    "\n",
    "def test_moe_LLM_prefill():\n",
    "    # Delete the current CSV file if it exists\n",
    "    if os.path.exists('/tmp/current_mixtral_8x7b_prefill_on_GH200.csv'):\n",
    "        os.remove('/tmp/current_mixtral_8x7b_prefill_on_GH200.csv')\n",
    "\n",
    "\n",
    "    # Generate the current result\n",
    "    GH200 = System(flops=2000, offchip_mem_bw=4900, compute_efficiency=0.8, memory_efficiency=0.8, bits='bf16',\n",
    "                off_chip_mem_size=144)\n",
    "\n",
    "    # Save the current result to a CSV file\n",
    "    current_df = get_model_df(model=create_inference_moe_prefill_layer(1024, \"mixtral_8x7b\"), system=GH200)\n",
    "    current_df.to_csv('/tmp/current_mixtral_8x7b_prefill_on_GH200.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "def test_moe_LLM_decode():\n",
    "    # Delete the current CSV file if it exists\n",
    "    if os.path.exists('/tmp/current_mixtral_8x7b_decode_on_GH200.csv'):\n",
    "        os.remove('/tmp/current_mixtral_8x7b_decode_on_GH200.csv')\n",
    "\n",
    "    # Generate the current result\n",
    "    GH200 = System(flops=2000, offchip_mem_bw=4900, compute_efficiency=0.8, memory_efficiency=0.8, bits='bf16',\n",
    "                off_chip_mem_size=144)\n",
    "\n",
    "    # Save the current result to a CSV file\n",
    "    current_df = get_model_df(model=create_inference_moe_decode_layer(1024, \"mixtral_8x7b\"), system=GH200)\n",
    "    current_df.to_csv('/tmp/current_mixtral_8x7b_decode_on_GH200.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dense_LLM_prefill()\n",
    "test_dense_LLM_decode()\n",
    "test_moe_LLM_prefill()\n",
    "test_moe_LLM_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.4', '2.2.2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenZ.Models.get_language_model import get_configs, create_inference_moe_prefill_layer, create_inference_moe_decode_layer\n",
    "\n",
    "MODEL_PATH = \"/tmp/genz/data/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = create_inference_moe_prefill_layer(input_sequence_length=10, name='gpt-2')\n",
    "assert file_name.endswith('.csv')\n",
    "assert 'gpt-2_prefix' in file_name\n",
    "df = pd.read_csv(os.path.join(MODEL_PATH, file_name), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QKV</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attend</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Out Proj</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>up+gate</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>down</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>3072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1   2     3   4   5  6  7\n",
       "0      Name     M   N     D   H   Z  Z  T\n",
       "1       QKV  2304  10   768   1   1  0  3\n",
       "2     Logit    12  10    10  64  12  3  4\n",
       "3    Attend    12  10    10  64  12  1  5\n",
       "4  Out Proj   768  10   768   1   1  0  3\n",
       "5   up+gate  3072  10   768   1   1  0  3\n",
       "6      down   768  10  3072   1   1  0  3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_AR_time() got an unexpected keyword argument 'num_AR_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m current_df \u001b[38;5;241m=\u001b[39m get_model_df(model\u001b[38;5;241m=\u001b[39mcreate_inference_moe_prefill_layer(\u001b[38;5;241m4096\u001b[39m, Model, tensor_parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), system\u001b[38;5;241m=\u001b[39mTPU)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## For GPT-2, the AR message size is 6 MB (4k tokens * 2 bytes)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m AR_time \u001b[38;5;241m=\u001b[39m \u001b[43mget_AR_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_AR_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTPU\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m prefill_output \u001b[38;5;241m=\u001b[39m prefill_moddeling(model \u001b[38;5;241m=\u001b[39m Model, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, input_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m     13\u001b[0m                             system_name \u001b[38;5;241m=\u001b[39m TPU, bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbf16\u001b[39m\u001b[38;5;124m'\u001b[39m, tensor_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, pipeline_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_AR_time() got an unexpected keyword argument 'num_AR_nodes'"
     ]
    }
   ],
   "source": [
    "from GenZ import prefill_moddeling, get_model_df, get_configs, System, create_inference_moe_prefill_layer, get_AR_time\n",
    "\n",
    "TPU = System(flops=300, offchip_mem_bw=1200, compute_efficiency=0.8, memory_efficiency=0.8, bits='bf16',\n",
    "            interchip_link_bw=50, interchip_link_latency=1)\n",
    "Model = 'gpt-2'\n",
    "# Save the current result to a CSV file\n",
    "current_df = get_model_df(model=create_inference_moe_prefill_layer(4096, Model, tensor_parallel=4), system=TPU)\n",
    "\n",
    "## For GPT-2, the AR message size is 6 MB (4k tokens * 2 bytes)\n",
    "AR_time = get_AR_time(data = 6*2**20, num_AR_nodes = 4, system = TPU)\n",
    "\n",
    "prefill_output = prefill_moddeling(model = Model, batch_size = 1, input_tokens = 4096,\n",
    "                            system_name = TPU, bits='bf16', tensor_parallel = 4, pipeline_parallel = 1, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Latency': 5.886358809914062,\n",
       " 'Throughput': 169.88430917866518,\n",
       " 'Runtime_breakdown': [0.7593637155140625, 0.6442450944, 4.482749999999999],\n",
       " 'is_offload': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefill_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18678124999999998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_AR_time(data = 6*2**20, num_AR_nodes = 4, system = TPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPU.interchip_link_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.isclose([5.886358809914062, 169.88430917866518, 0.7593637155140625],\n",
    "            [5.888638473, 169.8185420255, 0.7616433786,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genz_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
